{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55e27772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import igl\n",
    "from meshplot import plot\n",
    "import numpy as np\n",
    "import pygeodesic.geodesic as geodesic\n",
    "import networkx as nx\n",
    "import drawSvg as draw\n",
    "\n",
    "#----------functions from the previous lecture \"general unfolding polyhedra\" modified slightly to support polygonal mesh-----------\n",
    "\n",
    "# adds edges based on the adjacency of faces in the mesh\n",
    "# CHANGE FOR POLYGONAL MESH removed igl.triangle_triangle_adjacency and used is_adjacent function\n",
    "def add_edges_from_mesh(graph, faces):\n",
    "    for current_face_id, current_face in enumerate(faces):\n",
    "        for face_id, face in enumerate(faces):\n",
    "            if is_adjacent(current_face, face) and current_face_id != face_id:\n",
    "                graph.add_edge(current_face_id,face_id)\n",
    "\n",
    "# adds nodes to graph G for every face in mesh\n",
    "def add_nodes_from_mesh(graph, faces): [graph.add_node(face_id) for face_id, face in enumerate(faces)]\n",
    "\n",
    "# create networkx graph from given mesh\n",
    "def graph_from_mesh(faces):\n",
    "    graph = nx.Graph()\n",
    "    add_nodes_from_mesh(graph, faces)\n",
    "    add_edges_from_mesh(graph, faces)\n",
    "    return graph\n",
    "\n",
    "# returns a rotation matrix from a (unnormalized) axis and an angle\n",
    "def get_rotation_matrix(axis, angle):\n",
    "    from scipy.spatial.transform import Rotation\n",
    "    return Rotation.from_rotvec(axis/np.linalg.norm(axis) * angle).as_matrix()\n",
    "\n",
    "# returns a matrix that maps 3D space onto a 2D plane (the orientation of which is specified by 'face_normal').\n",
    "def get_2d_projection(face_normal):\n",
    "    xy_plane_normal = np.array([0,0,1])  #  aka 'the z-axis'\n",
    "    rotation_axis = np.cross(face_normal, xy_plane_normal)\n",
    "    angle = np.arccos(np.clip(np.dot(xy_plane_normal, face_normal), -1.0, 1.0))\n",
    "\n",
    "    discard_z_matrix = np.array([\n",
    "        [1, 0, 0],\n",
    "        [0, 1, 0]\n",
    "    ])\n",
    "\n",
    "    rotation_matrix = get_rotation_matrix(rotation_axis, angle)\n",
    "    return discard_z_matrix.dot(rotation_matrix)\n",
    "\n",
    "# find commone edge of two adjacent faces\n",
    "# CHANGE FOR POLYGONAL MESH removed the hardcoded loop iterator 3 to len(face_vertex_array_a) as face arrays can be of any size\n",
    "def find_common_edge(faces, face_id_a, face_id_b):\n",
    "    # make sure that the resulting vertex ids are clockwise wrt. source face\n",
    "    face_vertex_array_a = faces[face_id_a]\n",
    "    face_vertex_array_b = faces[face_id_b]\n",
    "    for i in range(len(face_vertex_array_a)):\n",
    "        if face_vertex_array_a[i] in face_vertex_array_b and face_vertex_array_a[(i+1) % len(face_vertex_array_a)] in face_vertex_array_b:\n",
    "            return (face_vertex_array_a[i], face_vertex_array_a[(i+1) % len(face_vertex_array_a)])\n",
    "\n",
    "    return None\n",
    "\n",
    "# get angle between the normals of two faces\n",
    "def dihedral_angle(face_normals, face_a_id, face_b_id):\n",
    "    return np.arccos(np.clip(np.dot(face_normals[face_a_id], face_normals[face_b_id]), -1.0, 1.0))\n",
    "\n",
    "# update from edge unfolding: added \"spanning_tree\" as an input instead of generating graph inside the function from the vertices and faces\n",
    "# update from general unfolding: added \"face_normals\" as an argument to simplyfy the code\n",
    "def unfold(vertices, faces, face_normals, spanning_tree):\n",
    "    polygons = []  # resulting polygons, represented as lists of 2D coordinates\n",
    "\n",
    "    source_face_id = 0\n",
    "    parent_dict = nx.dfs_predecessors(spanning_tree, source=source_face_id)  # format { node_id: parent_id, ... }\n",
    "    parent_dict[source_face_id] = None  # add the source face, as networkX is not doing this by default\n",
    "\n",
    "    for face_id, parent_face_id in parent_dict.items():\n",
    "        # retrieve the coordinates of current face\n",
    "        face_coordinates = [vertices[vertex_id] for vertex_id in faces[face_id]]\n",
    "        \n",
    "        # iterate over all parents and apply unfolding rotations accordingly\n",
    "        selected_face_id = face_id\n",
    "        selected_parent_face_id = parent_face_id\n",
    "\n",
    "        while selected_face_id != source_face_id:\n",
    "            # get edge between selected face and parent as tuple of two vertex_ids\n",
    "            hinge_edge = find_common_edge(faces, selected_parent_face_id, selected_face_id)\n",
    "            # apply unfolding transformation:\n",
    "            # - all face_coordinates are offset such that the hinge_edge aligns with the origin\n",
    "            # - then, the rotation around the hinge_edge is performed, such that the selected face\n",
    "            #   and the parent lay in the same plane\n",
    "            # - finally, we reverse the offset, such that the face ends up in its original position \n",
    "            offset = vertices[hinge_edge[0]]\n",
    "            rotation_angle = dihedral_angle(face_normals, selected_face_id, selected_parent_face_id)\n",
    "            rotation_axis = vertices[hinge_edge[0]] - vertices[hinge_edge[1]]\n",
    "            rotation_matrix = get_rotation_matrix(rotation_axis, rotation_angle)\n",
    "            # CHANGE FOR POLYGONAL MESH removed the hardcoded loop iterator 3 to len(face_coordinates) as face arrays can be of any size\n",
    "            for i in range(len(face_coordinates)):\n",
    "                face_coordinates[i] = rotation_matrix.dot(face_coordinates[i] - offset) + offset\n",
    "\n",
    "            # climbing up the tree\n",
    "            selected_face_id = selected_parent_face_id\n",
    "            selected_parent_face_id = parent_dict[selected_parent_face_id]\n",
    "\n",
    "        # project 3D coordinates into the 2D plane that\n",
    "        # CHANGE FOR POLYGONAL MESH removed the hardcoded loop iterator 3 to len(face_coordinates) as face arrays can be of any size\n",
    "        for i in range(len(face_coordinates)):\n",
    "            face_coordinates[i] = get_2d_projection(face_normals[source_face_id]).dot(face_coordinates[i])\n",
    "            \n",
    "        polygons.append(face_coordinates)\n",
    "\n",
    "    return polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f991316d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out if two normals point in the same direction\n",
    "def is_normal_same (normal_A, normal_B):\n",
    "    result = False\n",
    "    cross_ABAC = np.cross(normal_A, normal_B)\n",
    "    # if cross product is zero then normal point in same (or opposite direction)\n",
    "    if np.linalg.norm(cross_ABAC) < EPSILON: #  check if all elements in array are zero with EPSILON tolerance\n",
    "        result = True\n",
    "    return result\n",
    "\n",
    "# find out if one face is adjacent to another based on shared vertices\n",
    "def is_adjacent (current_face, face):\n",
    "    is_adjacent = False\n",
    "    common_vertices = np.intersect1d(current_face, face)\n",
    "    # if two or more vertices are shared the face is adjacent\n",
    "    if len(common_vertices) >=2:\n",
    "        is_adjacent = True\n",
    "    return is_adjacent\n",
    "\n",
    "# find out the adjacency array given polygonal faces\n",
    "def find_adjacency(polygonal_faces):\n",
    "    polgonal_adjacency =[]\n",
    "    for current_face_id, current_face in enumerate(polygonal_faces):\n",
    "        adjacency =[]\n",
    "        for face_id, face in enumerate(polygonal_faces):\n",
    "            if is_adjacent(current_face, face) and current_face_id != face_id:\n",
    "                adjacency.append(face_id)\n",
    "        polgonal_adjacency.append(adjacency)\n",
    "    return polgonal_adjacency\n",
    "\n",
    "# check if a given face is adjacent, shares a normal and has not been visited before\n",
    "# as a candidate for merging\n",
    "def find_adjacent_unvisited_faces_with_same_normal (current_face, current_normal, visited_faces, faces, face_normals):\n",
    "    adjacent_faces = []\n",
    "    for face_id, face in enumerate(faces):\n",
    "        if is_adjacent(current_face, face) and is_normal_same(current_normal,face_normals[face_id]) and visited_faces[face_id] == 0:\n",
    "            adjacent_faces.append(face_id)\n",
    "    return adjacent_faces\n",
    "\n",
    "# create polyhedral mesh from triangulated mesh by combining adjacent triangular faces that have the same normal\n",
    "# into polygonal faces\n",
    "def build_polyhedral_mesh(faces, face_normals):\n",
    "    # keep track of faces that have been visited and merged\n",
    "    visited_faces = np.zeros(len(faces))\n",
    "    polygonal_faces = []\n",
    "    polygonal_face_normals = []\n",
    "    # loop through all triangular faces of the mesh\n",
    "    for face_id, face in enumerate(faces):\n",
    "        # avoid faces that have been previously visited and merged\n",
    "        if visited_faces[face_id] == 0:\n",
    "            # get the normal of the current triangle face (from igl) and add it to the list of normals for polygonal faces\n",
    "            normal = face_normals[face_id]\n",
    "            polygonal_face_normals.append(list(normal))\n",
    "            # set the current face as visited\n",
    "            visited_faces[face_id] = 1\n",
    "            # find the faces that meet the three criteria: adjacent, normals point in the same direction and not already visited\n",
    "            adjacent_face_ids = find_adjacent_unvisited_faces_with_same_normal (face, normal, visited_faces, faces, face_normals)\n",
    "            # edge case handling: some faces might not have any faces that meet this criteria e.g. face on side of triangular prism\n",
    "            # in this case, add the dace itself to the polygonal face list\n",
    "            if len(adjacent_face_ids) < 1:\n",
    "                polygonal_faces.append(list(face))\n",
    "            # regular case\n",
    "            else:\n",
    "                # repeat until all adjacent faces with same normals have been visited and merged\n",
    "                while len(adjacent_face_ids) > 0:\n",
    "                    # loop thorugh all faces that meet the criteria for a merge\n",
    "                    for adjacent_face_id in adjacent_face_ids:\n",
    "                        # ignore previously visited faces\n",
    "                        if visited_faces[adjacent_face_id] != 1:\n",
    "                            visited_faces[adjacent_face_id] = 1\n",
    "                            # get the vertex array of the adjacent face\n",
    "                            adjacent_face = faces[adjacent_face_id]\n",
    "                            # merge the adjacent face and update the polygonal face\n",
    "                            face = merge_triangles(face, adjacent_face)\n",
    "                        \n",
    "                    # find the faces that meet the three criteria for the polygonal face: adjacent, normals point in the same direction and not already visited\n",
    "                    adjacent_face_ids = find_adjacent_unvisited_faces_with_same_normal (face, normal, visited_faces, faces, face_normals) \n",
    "                # add the completed polygonal face to the polygonal face list\n",
    "                polygonal_faces.append(face)\n",
    "    return polygonal_faces, polygonal_face_normals\n",
    "\n",
    "# merge two faces together. \"face\" is the polygonal face that will be merged into, while \"adjacent_face\" is the face to be merged. both are arrays of vertices\n",
    "def merge_triangles(face, adjacent_face):\n",
    "    # convert to list for easier handling\n",
    "    result_face = list(face)\n",
    "    # we find the common vertices between face and adjacent face and their location\n",
    "    common_vertices, common_vertices_index, _ = np.intersect1d(result_face, adjacent_face, return_indices=True)\n",
    "    sorted_index = np.sort(common_vertices_index)\n",
    "    # if there are only two common vertices = edge is shared\n",
    "    if len(sorted_index) == 2:\n",
    "        # figure out which vertex in the triangle is the one that needs to be added\n",
    "        incoming_vertex = set(adjacent_face).difference(common_vertices).pop()\n",
    "        # find location to insert the new vertex\n",
    "        # if vertices are next to each other then insert the new vertex at the bigger index e.g. [1, 2, 0] and new vertex goes between 2 and 0 i.e. insert it at index 2\n",
    "        if abs(sorted_index[0]-sorted_index[1]) == 1:\n",
    "            insert_location = sorted_index[1]\n",
    "        # if vertices are not next to each other i.e. at the edges of the array then insert the new vertex at the smaller index, which would be the bigger index in the circular array, e.g. [0, 1, 2] and new vertex goes between 2 and 0, so smaller number is bigger index i.e insert it at index 0.\n",
    "        else:\n",
    "            insert_location = sorted_index[0]\n",
    "        # and insert it\n",
    "        result_face.insert(insert_location, incoming_vertex)\n",
    "        \n",
    "    # edge case handling when all three vertices of the triangular face are already part of the polygonal face array\n",
    "    # e.g. if the preceeding faces have encircled the face before encountering it\n",
    "    # = two or three edges are shared\n",
    "    else:\n",
    "        # these three vertices will occur in sequence in the polygonal face array (difference sequence then triangular face array)\n",
    "        # delete the vertex in the middle of this sequence to add the triangle i.e. deleting two edges and creating a new one\n",
    "        # boxy_2 is the example .stl that has this problem\n",
    "\n",
    "        # if both start and end index are there then the vertex to be deleted is the last one in the sort i.e. circular array\n",
    "        # e.g. [10  4  2] are the vertices in the face array\n",
    "        # [4, 5, 3, 0, 1, 8, 9, 10, 2] are the vertices of the polygonal array\n",
    "        # [8 0 7] are the locations in the polygonal array, [0 7 8] are the sorted result, delete vertex at location 8\n",
    "        if 0 in sorted_index and len(result_face)-1 in sorted_index:\n",
    "            del result_face[sorted_index[2]]\n",
    "        # otherwise the sequence is in the middle of the array and the index in the middle should be deleted  \n",
    "        else:\n",
    "            del result_face[sorted_index[1]]      \n",
    "    return result_face\n",
    "\n",
    "# create the strip unfolding spanning tree\n",
    "def strip_unfold(faces, normals, adjacency):\n",
    "    unfolding_tree = nx.Graph()\n",
    "\n",
    "    # find suitable strip faces\n",
    "    all_faces = list(range(len(faces)))\n",
    "\n",
    "    ignored_normals = [\n",
    "        np.array([1, 0, 0]),\n",
    "        np.array([0, 1, 0]),\n",
    "        np.array([0, 0, 1]),\n",
    "    ]\n",
    "    \n",
    "    # create a filter prefix for all ignored normals\n",
    "    filter_prefixs = [lambda f: not is_normal_same(normals[f], i) for i in\n",
    "        ignored_normals]\n",
    "\n",
    "    # find best strip\n",
    "    # strip faces are all_faces except with certain normal\n",
    "    # create all possible strips by filtering all_faces to all filter prefixs\n",
    "    pos_strips = [set(filter(prefix, all_faces)) for prefix in filter_prefixs]\n",
    "\n",
    "    # use the best (= longest) strip in further code\n",
    "    strip_faces = max(pos_strips, key=lambda a: len(a))\n",
    "\n",
    "    # wing faces are all_faces which are not strip_faces\n",
    "    wing_faces = set(all_faces).difference(strip_faces)\n",
    "\n",
    "    # build a 'circle' out of the strip_faces\n",
    "    for face in strip_faces:\n",
    "        for adj_face in adjacency[face]:\n",
    "            if adj_face in strip_faces:\n",
    "                unfolding_tree.add_edge(face, adj_face)\n",
    "    # minimum_spanning_tree will disconnect one of the connections and build a strip\n",
    "    unfolding_tree = nx.minimum_spanning_tree(unfolding_tree)\n",
    "\n",
    "    unattachable = []\n",
    "    # add wing faces on first adjacency found\n",
    "    for face in wing_faces:\n",
    "        adj_faces = set(adjacency[face])\n",
    "        # all possible positions where the face could attach \n",
    "        pos_positions = list(adj_faces.intersection(strip_faces))\n",
    "\n",
    "        # check if wing is connectable\n",
    "        if len(pos_positions) == 0:\n",
    "            # if not add it to unattachable array to build subassembly later\n",
    "            unattachable.append(face)\n",
    "        else:\n",
    "            # if so add_edge to unfolding_tree itsef and to the strip so later a wing\n",
    "            # could be attached to the newly attached wing f\n",
    "\n",
    "            # currently choosing just the first found position to attach the\n",
    "            # wing, here optimizations could be done\n",
    "            unfolding_tree.add_edge(face, pos_positions[0])\n",
    "            strip_faces.add(face)\n",
    "\n",
    "    return unfolding_tree, unattachable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb466f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "     width=\"1000\" height=\"1000\" viewBox=\"-500.0 -500.0 1000 1000\">\n",
       "<defs>\n",
       "</defs>\n",
       "<path d=\"M-190.22100295882157,126.44650279488255 L-190.2210056906856,138.94650279488314 L-152.72100449859167,138.94650622210344 L-142.72100448608623,138.94650459289736 L-142.7210044860851,126.4465045928972 L-142.72100448608396,113.94650459289701 L-142.72100448608396,101.44650459289686 L-92.72100226346333,101.4465059836094 L-92.7210042999709,88.94650598360955 L-142.72100448608282,88.9465045928967 L-152.72100429997167,88.94650622210271 L-190.2210042999727,88.94650279488225 L-190.22100226346512,101.4465027948821 L-152.7210046476499,101.44650622210294 L-152.72100499532812,113.94650622210315 L-152.72100415091344,126.4465062221032 Z\" fill=\"#eeee00\" stroke=\"#000\" stroke-width=\"0.1\" />\n",
       "<path d=\"M-190.22100911790577,176.446502794883 L-190.22101026031248,188.946502794883 L-152.72100906821854,188.94650622210324 L-142.72100905571332,188.9465071360286 L-142.7210079133066,176.4465071360286 L-142.7210067708999,163.9465071360287 L-142.72100562849317,151.44650713602874 L-142.72100448608646,138.9465071360288 L-152.72100449859164,138.94650622210344 L-190.2210056906856,138.94650279488314 L-190.22100683309233,151.4465027948831 L-152.72100564099838,151.44650622210338 L-152.7210067834051,163.94650622210332 L-152.72100792581182,176.44650622210327 Z\" fill=\"#eeee00\" stroke=\"#000\" stroke-width=\"0.1\" />\n",
       "<path d=\"M-190.22101368753232,226.44650279488405 L-190.22101800885335,238.9465027948833 L-152.72101800885227,238.9465062221031 L-142.7210181949639,238.9465096791599 L-92.72101800885251,238.94651742770077 L-92.7210136875315,226.44651742770156 L-142.7210159101516,226.44650967915996 L-142.72101362533814,213.9465096791599 L-142.72101134052585,201.44650967916 L-142.72100905571355,188.94650967916004 L-152.72100906821854,188.94650622210324 L-190.22101026031248,188.946502794883 L-190.2210098132619,201.44650279488386 L-152.72101100535372,201.44650622210332 L-152.72101413458185,213.94650622210295 L-152.72101607171706,226.4465062221031 Z\" fill=\"#eeee00\" stroke=\"#000\" stroke-width=\"0.1\" />\n",
       "<path d=\"M-190.22101095566842,213.94650279488377 L-152.72101214776023,213.94650622210324 L-152.72101100535372,201.44650622210332 L-190.2210098132619,201.44650279488386 Z\" fill=\"#eeee00\" stroke=\"#000\" stroke-width=\"0.1\" />\n",
       "<path d=\"M-190.22101368753238,226.44650279488405 L-152.72101607171706,226.4465062221031 L-152.72101492931063,213.9465062221031 L-190.22101254512594,213.94650279488405 Z\" fill=\"#eeee00\" stroke=\"#000\" stroke-width=\"0.1\" />\n",
       "<path d=\"M-190.2210098132619,201.44650279488386 L-190.22101026031248,188.946502794883 L-202.72101026031248,188.94650324193353 L-202.7210098132619,201.44650324193447 Z\" fill=\"#eeee00\" stroke=\"#000\" stroke-width=\"0.1\" />\n",
       "<path d=\"M-190.22100911790577,176.446502794883 L-152.72100792581182,176.44650622210327 L-152.7210075781336,163.94650622210304 L-190.22100638604175,163.9465027948824 Z\" fill=\"#eeee00\" stroke=\"#000\" stroke-width=\"0.1\" />\n",
       "<path d=\"M-190.22100638604175,163.94650279488403 L-152.7210075781336,163.94650622210347 L-152.72100564099838,151.44650622210338 L-190.22100683309233,151.4465027948831 Z\" fill=\"#eeee00\" stroke=\"#000\" stroke-width=\"0.1\" />\n",
       "<path d=\"M-190.22100564099716,151.4465027948832 L-202.7210056409969,151.4465016524765 L-202.72100678340365,163.94650165247643 L-202.72100792581034,176.4465016524764 L-190.2210079258106,176.4465027948831 L-190.2210090682173,188.94650279488306 L-177.7210090682175,188.9465039372898 L-165.2210090682183,188.94650507969652 L-165.2210079258116,176.44650507969655 L-152.72100792581182,176.44650622210327 L-152.7210067834051,163.94650622210332 L-152.72100564099838,151.44650622210338 L-165.22100564099813,151.44650507969664 L-165.2210044985914,138.9465050796967 L-177.72100449859067,138.94650393728998 L-190.22100449859042,138.94650279488326 Z\" fill=\"#eeee00\" stroke=\"#000\" stroke-width=\"0.1\" />\n",
       "<path d=\"M-190.22100395229447,76.44650327171946 L-190.2210042999727,88.94650327171946 L-152.7210042999716,88.94650431475412 L-142.72100448608282,88.9465045928967 L-92.7210042999709,88.94650598360955 L-92.72100395229268,76.44650598360955 L-92.72100360461445,63.946505983609555 L-92.72100325693626,51.44650598360955 L-92.72100290925805,38.94650598360955 L-142.72100309536998,38.94650459289669 L-152.72100290925874,38.94650431475412 L-190.22100290925988,38.94650327171948 L-190.22100325693805,51.44650327171948 L-152.72100325693697,51.446504314754115 L-152.7210036046152,63.94650431475412 L-152.7210039522934,76.44650431475412 Z\" fill=\"#eeee00\" stroke=\"#000\" stroke-width=\"0.1\" />\n",
       "<path d=\"M-190.2210004257019,63.94650327171916 L-152.72100280988658,63.946504314754364 L-152.72100325693697,51.446504314754115 L-190.22100325693805,51.44650327171948 Z\" fill=\"#eeee00\" stroke=\"#000\" stroke-width=\"0.1\" />\n",
       "<path d=\"M-202.72100325693773,51.446506102955645 L-202.72100042570156,63.94650610295534 L-190.2210004257019,63.94650327171916 L-190.22100325693805,51.44650327171948 Z\" fill=\"#eeee00\" stroke=\"#000\" stroke-width=\"0.1\" />\n",
       "<path d=\"M-190.22100395229447,76.44650327171946 L-152.7210039522934,76.44650431475412 L-152.72100280988658,63.94650431475394 L-190.2210004257019,63.946503271719976 Z\" fill=\"#eeee00\" stroke=\"#000\" stroke-width=\"0.1\" />\n",
       "<path d=\"M-190.22100295882157,126.44650279488255 L-152.72100415091344,126.4465062221032 L-152.7210030085065,113.94650622210324 L-190.22100181641466,113.94650279488259 Z\" fill=\"#eeee00\" stroke=\"#000\" stroke-width=\"0.1\" />\n",
       "<path d=\"M-190.22100340587215,113.94650279488202 L-152.7210057900569,113.94650622210287 L-152.72100464764986,101.44650622210294 L-190.22100226346512,101.4465027948821 Z\" fill=\"#eeee00\" stroke=\"#000\" stroke-width=\"0.1\" />\n",
       "<path d=\"M-92.72100330649769,138.9465059836094 L-92.72100295881957,126.44650598360938 L-92.72100261114146,113.94650598360938 L-92.72100226346333,101.4465059836094 L-142.72100448608396,101.44650459289686 L-142.7210048337621,113.94650459289684 L-142.7210051814402,126.44650459289686 L-142.72100552911832,138.94650459289687 L-142.72100587679643,151.44650459289684 L-92.7210036541758,151.44650598360937 Z\" fill=\"#eeee00\" stroke=\"#000\" stroke-width=\"0.1\" />\n",
       "<path d=\"M-67.72100429997123,88.94650191059442 L-80.22100429997104,88.94650394710199 L-92.7210042999709,88.94650598360955 L-92.72100226346333,101.4465059836094 L-80.22100226346348,101.44650394710183 L-67.72100226346366,101.44650191059426 L-55.221002263463845,101.4464998740867 L-42.721002263464,101.44649783757913 L-42.72100429997157,88.94649783757929 L-55.22100429997141,88.94649987408685 Z\" fill=\"#eeee00\" stroke=\"#000\" stroke-width=\"0.1\" />\n",
       "<path d=\"M-202.7210029588213,126.44650006301853 L-202.7210056906853,138.94650006301913 L-190.2210056906856,138.94650279488314 L-190.22100295882157,126.44650279488255 Z\" fill=\"#eeee00\" stroke=\"#000\" stroke-width=\"0.1\" />\n",
       "<path d=\"M-202.72100429997255,88.94650483138982 L-202.72100226346498,101.44650483138966 L-190.22100226346512,101.4465027948821 L-190.2210042999727,88.94650279488225 Z\" fill=\"#eeee00\" stroke=\"#000\" stroke-width=\"0.1\" />\n",
       "<path d=\"M-142.72100448608396,101.44650459289686 L-142.72100448608396,113.94650459289701 L-142.72100448608396,126.4465045928972 L-142.72100448608396,138.94650459289736 L-130.22100448608396,138.94650459289736 L-117.72100448608397,138.94650459289736 L-105.22100448608397,138.94650459289736 L-92.72100448608397,138.94650459289736 L-92.72100448608397,126.4465045928972 L-92.72100448608397,113.94650459289701 L-92.72100448608397,101.44650459289686 L-105.22100448608397,101.44650459289686 L-117.72100448608397,101.44650459289686 L-130.22100448608396,101.44650459289686 Z\" fill=\"#eeee00\" stroke=\"#000\" stroke-width=\"0.1\" />\n",
       "</svg>"
      ],
      "text/plain": [
       "<drawSvg.drawing.Drawing at 0x2660369cc40>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_vertices, raw_faces = igl.read_triangle_mesh(\"chair.stl\")\n",
    "vertices, faces, _ = igl.remove_duplicates(raw_vertices, raw_faces, 0.00001)\n",
    "face_normals = igl.per_face_normals(vertices, faces, np.ones((1, 3)))\n",
    "\n",
    "EPSILON = 1e-5\n",
    "\n",
    "polygonal_faces, polygonal_face_normals= build_polyhedral_mesh(faces, face_normals)\n",
    "\n",
    "# find the adjacency list array for the polygonal faces\n",
    "polgonal_adjacency = find_adjacency(polygonal_faces)\n",
    "\n",
    "# find the spanning tree for the strip unfolding\n",
    "unfolding_tree, unattachable = strip_unfold(polygonal_faces, polygonal_face_normals, polgonal_adjacency)\n",
    "\n",
    "# unfold along the unfolding spanning tree\n",
    "polygons = unfold(vertices, polygonal_faces, polygonal_face_normals, unfolding_tree)\n",
    "\n",
    "# generate svg visualization\n",
    "drawing = None\n",
    "drawing = draw.Drawing(1000, 1000, origin='center')\n",
    "for polygon in polygons:\n",
    "    # polygon = [coords[0:2] for coords in polygon]\n",
    "    drawing.append(draw.Lines(*np.array(polygon).flatten()*5,\n",
    "                   close=True, fill='#eeee00', stroke='#000', stroke_width=.1))\n",
    "\n",
    "drawing.rasterize()\n",
    "drawing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
